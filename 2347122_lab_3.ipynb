{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Data Preprocessing"
      ],
      "metadata": {
        "id": "yHXMTXaW2Biy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RE90G0_N09Oz",
        "outputId": "e10a9cee-4a42-44a7-9d08-7ffd2b316757"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Load dataset\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# Normalize pixel values to range between 0 and 1\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0\n",
        "\n",
        "# Convert class labels into one-hot encoded format\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "b. Data Augmentation (Optional)\n",
        "\n",
        "Data augmentation can improve the generalization of the model. We'll apply random flips, rotations, and shifts.:"
      ],
      "metadata": {
        "id": "9EoUR-TV2Fjx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    horizontal_flip=True)\n",
        "datagen.fit(x_train)\n"
      ],
      "metadata": {
        "id": "2JPBXOTi1EA8"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.NETWORK ARCHITRCTURE DESIGN"
      ],
      "metadata": {
        "id": "Nw0E4tWd1I_M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "# Input Layer + Convolutional Layers\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# Flatten the data for the Dense Layers\n",
        "model.add(Flatten())\n",
        "\n",
        "# Fully Connected Layers\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "# Output Layer\n",
        "model.add(Dense(10, activation='softmax'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CXxdsnd_1GzO",
        "outputId": "ded7bf4d-e9b7-4445-ebe8-09209c8d77b3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Justification:\n",
        "\n",
        "\n",
        "Conv2D layers capture spatial features from the images.\n",
        "\n",
        "MaxPooling reduces dimensionality, preventing overfitting.\n",
        "\n",
        "Dropout is used to regularize the model.\n",
        "\n",
        "Softmax in the output layer ensures proper multi-class classification."
      ],
      "metadata": {
        "id": "DJVeIOiK1P6S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Activation Functions\n",
        "We'll use ReLU for hidden layers because:\n",
        "\n",
        "ReLU accelerates convergence in deeper networks.\n",
        "It helps to avoid vanishing gradient problems.\n",
        "The softmax activation in the output layer ensures multi-class classification."
      ],
      "metadata": {
        "id": "oh6hSMdQ1Umt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##4. Loss Function and Optimizer\n",
        "\n",
        "Since this is a multi-class classification problem, we’ll use categorical crossentropy. Additionally, we can compare the performance of Mean Squared Error (MSE) and Hinge Loss."
      ],
      "metadata": {
        "id": "xmP3MEh61epK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    loss='categorical_crossentropy',  # Main loss function\n",
        "    optimizer='adam',  # Adam optimizer\n",
        "    metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "KZ5brtcc1R36"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Justification for Adam Optimizer:\n",
        "\n",
        "Adam combines the benefits of SGD with momentum and RMSprop.\n",
        "It dynamically adjusts the learning rate based on gradients.\n",
        "Learning Rate: If the model is not converging, reducing the learning rate can help stabilize training.\n"
      ],
      "metadata": {
        "id": "2CuWrVJU1ymR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Training the Model"
      ],
      "metadata": {
        "id": "lO1VWNQd161n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the model\n",
        "history = model.fit(datagen.flow(x_train, y_train, batch_size=64),\n",
        "                    epochs=5,validation_data=(x_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "698Pgwr-1acM",
        "outputId": "3e35263a-8ef5-47ca-e6e1-b21114c9845a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 121ms/step - accuracy: 0.2433 - loss: 2.0168 - val_accuracy: 0.4539 - val_loss: 1.4956\n",
            "Epoch 2/5\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 115ms/step - accuracy: 0.3945 - loss: 1.6631 - val_accuracy: 0.4838 - val_loss: 1.4268\n",
            "Epoch 3/5\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 113ms/step - accuracy: 0.4304 - loss: 1.5623 - val_accuracy: 0.5284 - val_loss: 1.2965\n",
            "Epoch 4/5\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 112ms/step - accuracy: 0.4630 - loss: 1.4904 - val_accuracy: 0.5484 - val_loss: 1.2466\n",
            "Epoch 5/5\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 114ms/step - accuracy: 0.4800 - loss: 1.4442 - val_accuracy: 0.5781 - val_loss: 1.1992\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Model Evaluation"
      ],
      "metadata": {
        "id": "F-48V2T42QNT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate on test data\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print('Test accuracy:', test_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KqidWTIA2S2f",
        "outputId": "1dd5a815-caa2-4a18-e98c-5311504e0915"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.5801 - loss: 1.2049\n",
            "Test accuracy: 0.5781000256538391\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "y_pred = np.argmax(model.predict(x_test), axis=-1)\n",
        "y_true = np.argmax(y_test, axis=-1)\n",
        "\n",
        "# Precision, Recall, F1-Score\n",
        "print(classification_report(y_true, y_pred))\n",
        "\n",
        "# Confusion Matrix\n",
        "print(confusion_matrix(y_true, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LToO4eYa2U-G",
        "outputId": "2e190bf1-b79f-4e3b-d1d6-3a35ebc55821"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.56      0.64      1000\n",
            "           1       0.62      0.79      0.69      1000\n",
            "           2       0.60      0.22      0.32      1000\n",
            "           3       0.45      0.32      0.37      1000\n",
            "           4       0.54      0.46      0.49      1000\n",
            "           5       0.51      0.55      0.53      1000\n",
            "           6       0.56      0.75      0.65      1000\n",
            "           7       0.59      0.69      0.63      1000\n",
            "           8       0.75      0.68      0.71      1000\n",
            "           9       0.49      0.78      0.60      1000\n",
            "\n",
            "    accuracy                           0.58     10000\n",
            "   macro avg       0.59      0.58      0.56     10000\n",
            "weighted avg       0.59      0.58      0.56     10000\n",
            "\n",
            "[[555  73  46  13  20   6   9  21 114 143]\n",
            " [  2 794   0   2   1   2   8   1   5 185]\n",
            " [ 73  28 221  65 183 122 166  66  30  46]\n",
            " [  8  42  30 318  46 249 132  78  23  74]\n",
            " [ 26  14  24  45 456  42 182 172  15  24]\n",
            " [  4  20  25 132  57 547  52 103  14  46]\n",
            " [  2  29  10  80  40  14 754  11   2  58]\n",
            " [  7  12   4  35  39  88  20 685   4 106]\n",
            " [ 59 111   4  14   6   5   5  11 676 109]\n",
            " [  9 167   2  10   1   1   7  10  18 775]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Optimization Strategies\n",
        "\n",
        "Early Stopping can be implemented to prevent overfitting by halting training when the validation loss stops improving.\n",
        "\n",
        "Learning Rate Scheduling helps reduce the learning rate progressively to fine-tune the model towards the end of training.\n",
        "\n",
        "Weight Initialization: Efficient weight initialization (like Xavier initialization) ensures the model starts with optimal weight distributions, avoiding vanishing or exploding gradients."
      ],
      "metadata": {
        "id": "Yvz50wAg2XVV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "# Early stopping to prevent overfitting\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "# Learning rate scheduling\n",
        "lr_schedule = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5)\n",
        "\n",
        "history = model.fit(datagen.flow(x_train, y_train, batch_size=64),\n",
        "                    epochs=5,\n",
        "                    validation_data=(x_test, y_test),\n",
        "                    callbacks=[early_stopping, lr_schedule])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kaUF6Lqi2dRa",
        "outputId": "d6a38882-aba7-4e6e-8e1a-75e7ad75d999"
      },
      "execution_count": 9,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 116ms/step - accuracy: 0.4933 - loss: 1.4156 - val_accuracy: 0.5918 - val_loss: 1.1445 - learning_rate: 0.0010\n",
            "Epoch 2/5\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 113ms/step - accuracy: 0.5070 - loss: 1.3822 - val_accuracy: 0.6046 - val_loss: 1.0969 - learning_rate: 0.0010\n",
            "Epoch 3/5\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 113ms/step - accuracy: 0.5090 - loss: 1.3544 - val_accuracy: 0.6020 - val_loss: 1.1220 - learning_rate: 0.0010\n",
            "Epoch 4/5\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 112ms/step - accuracy: 0.5139 - loss: 1.3480 - val_accuracy: 0.6098 - val_loss: 1.0858 - learning_rate: 0.0010\n",
            "Epoch 5/5\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 111ms/step - accuracy: 0.5288 - loss: 1.3171 - val_accuracy: 0.6077 - val_loss: 1.1046 - learning_rate: 0.0010\n"
          ]
        }
      ]
    }
  ]
}