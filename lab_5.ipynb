{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ehMAM2ekFk7D",
        "outputId": "7dfadd71-b701-43e2-fb37-199de81051c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/puneet6060/intel-image-classification?dataset_version_number=2...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 346M/346M [00:13<00:00, 27.3MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/puneet6060/intel-image-classification/versions/2\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"puneet6060/intel-image-classification\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "# Set dataset paths (Update according to your directory structure)\n",
        "train_dir = '/root/.cache/kagglehub/datasets/puneet6060/intel-image-classification/versions/2/seg_train'\n",
        "test_dir = '/root/.cache/kagglehub/datasets/puneet6060/intel-image-classification/versions/2/seg_test'"
      ],
      "metadata": {
        "id": "jMSRuiBHJ_YM"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "IMG_HEIGHT = 150\n",
        "IMG_WIDTH = 150\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 20\n",
        "\n",
        "# Data augmentation and loading the dataset\n",
        "train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                                   rotation_range=20,\n",
        "                                   zoom_range=0.2,\n",
        "                                   horizontal_flip=True)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(train_dir,\n",
        "                                                    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                    batch_size=BATCH_SIZE,\n",
        "                                                    class_mode='categorical')\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(test_dir,\n",
        "                                                  target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                  batch_size=BATCH_SIZE,\n",
        "                                                  class_mode='categorical')\n",
        "\n",
        "# Model Architecture\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    BatchNormalization(),\n",
        "\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    BatchNormalization(),\n",
        "\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    BatchNormalization(),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(6, activation='softmax')  # 6 categories\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.001),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gp4aVBiHFzwH",
        "outputId": "dec0b415-87a4-4f26-8c64-d1f52d439475"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 14034 images belonging to 1 classes.\n",
            "Found 3000 images belonging to 1 classes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Define image dimensions and parameters\n",
        "image_height, image_width = 150, 150  # Adjust as per your dataset\n",
        "channels = 3  # 3 for RGB images\n",
        "batch_size = 32\n",
        "n_classes = 6  # Adjust this to the number of classes in your dataset\n",
        "\n",
        "# Data augmentation and rescaling for training and validation datasets\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Create training data generator\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    '/root/.cache/kagglehub/datasets/puneet6060/intel-image-classification',\n",
        "    target_size=(image_height, image_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='sparse'  # Use 'sparse' for integer labels\n",
        ")\n",
        "\n",
        "# Create validation data generator\n",
        "val_generator = val_datagen.flow_from_directory(\n",
        "    '/root/.cache/kagglehub/datasets/puneet6060/intel-image-classification',\n",
        "    target_size=(image_height, image_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='sparse'  # Use 'sparse' for integer labels\n",
        ")\n",
        "\n",
        "# Build the model\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(image_height, image_width, channels)),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(n_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(train_generator, epochs=1, validation_data=val_generator)\n",
        "\n",
        "# Evaluate the model on validation data\n",
        "val_loss, val_accuracy = model.evaluate(val_generator)\n",
        "print(f'Validation Loss: {val_loss}, Validation Accuracy: {val_accuracy}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gTwcJTfDKy5e",
        "outputId": "6ff34780-1213-4d0e-d18b-5cfb48fede8b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 24335 images belonging to 1 classes.\n",
            "Found 24335 images belonging to 1 classes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m761/761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1731s\u001b[0m 2s/step - accuracy: 0.9905 - loss: 0.0183 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
            "\u001b[1m761/761\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m374s\u001b[0m 491ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
            "Validation Loss: 0.0, Validation Accuracy: 1.0\n"
          ]
        }
      ]
    }
  ]
}